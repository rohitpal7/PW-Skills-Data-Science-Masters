{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551e8ee9-2f0c-4697-9bce-473d296ba3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1. What is the KNN algorithm?\n",
    "#Ans.\n",
    "#The K-nearest neighbors (KNN) algorithm is a type of machine learning algorithm used for both classification and regression tasks. \n",
    "#It is a non-parametric algorithm, which means it does not make any assumptions about the underlying distribution of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dffad2a-3da1-4f6c-bd2a-5e059f2e0f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2. How do you choose the value of K in KNN?\n",
    "#Ans.\n",
    "#Choosing the value of K in KNN is an important step in optimizing the performance of the algorithm. \n",
    "#The choice of K depends on the problem at hand, and there is no hard and fast rule for choosing the value of K.\n",
    "\n",
    "#However, there are a few common approaches for selecting the value of K: Cross-validation, Rule of thumb, Domain knowledge, Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147f96e1-4a69-4c86-9224-7a7452ab6cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3. What is the difference between KNN classifier and KNN regressor?\n",
    "#Ans.\n",
    "#The main difference between KNN classifier and KNN regressor lies in the type of prediction they make.\n",
    "#In KNN classification, the algorithm predicts the class or category of a new data point based on the majority class of its K nearest neighbors in the training set. \n",
    "#in KNN regression, the algorithm predicts the output value of a new data point based on the average value of its K nearest neighbors in the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dd9ff7-ce1a-4c6f-ac15-9e0faadfc02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4. How do you measure the performance of KNN?\n",
    "#Ans.\n",
    "#To measure the performance of KNN, various evaluation metrics can be used depending on the problem being solved. \n",
    "#The most commonly used evaluation metrics for KNN are: Accuracy, Precision and Recall, F1-score, Mean squared error (MSE), R-squared (RÂ²)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dd1b5d-6ebf-44f4-9012-d4ace8f368af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5. What is the curse of dimensionality in KNN?\n",
    "#Ans.\n",
    "#The curse of dimensionality refers to the phenomenon where the performance of KNN deteriorates as the number of dimensions or features in the data increases. \n",
    "#In high-dimensional spaces, the distance between any two points becomes larger, and the number of data points needed to accurately represent the data distribution increases exponentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e1178e-9e81-4d99-ae7f-efde3e567607",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6. How do you handle missing values in KNN?\n",
    "#Ans.\n",
    "#Handling missing values in KNN is a challenging task as the algorithm relies on the similarity between data points to make predictions. \n",
    "#One approach to handle missing values in KNN is to impute or fill in the missing values before applying the algorithm. \n",
    "#There are several techniques for imputing missing values in KNN, including: Mean/median imputation, Mode imputation, Regression imputation, KNN imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28e2717-82a3-45fe-8a51-c2632b67f6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7. Compare and contrast the performance of the KNN classifier and regressor. Which one is better for which type of problem?\n",
    "#Ans.\n",
    "#The KNN classifier and regressor have different performance characteristics and are suitable for different types of problems.\n",
    "#The KNN classifier is used for classification problems where the goal is to predict the class label of a new data point based on its similarity to the training data. \n",
    "#The KNN regressor is used for regression problems where the goal is to predict a continuous variable based on the similarity to the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb845c9-d7e5-4cd7-ac05-989efba192e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q8. What are the strengths and weaknesses of the KNN algorithm for classification and regression tasks, and how can these be addressed?\n",
    "#Ans.\n",
    "#The KNN algorithm has several strengths and weaknesses for classification and regression tasks:\n",
    "\n",
    "#Strengths: Non-parametric, Intuitive, Good performance on small datasets, Versatility\n",
    "#Weaknesses: Computationally expensive, Sensitive to the choice of hyperparameters, Curse of dimensionality, Imbalanced datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ac64f2-ec4a-4c56-962c-549d353a7055",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q9. What is the difference between Euclidean distance and Manhattan distance in KNN?\n",
    "#Ans.\n",
    "#Euclidean distance and Manhattan distance are two common distance metrics used in KNN to calculate the distance between data points.\n",
    "#Euclidean distance is the straight-line distance between two points in Euclidean space. \n",
    "#The formula for Euclidean distance between two points (p1,q1) and (p2,q2) in a two-dimensional space is:\n",
    "distance = sqrt((p1-p2)^2 + (q1-q2)^2)\n",
    "\n",
    "#Manhattan distance, also known as taxicab distance or L1 distance, is the distance between two points measured along the axes at right angles.\n",
    "#he formula for Manhattan distance between two points (p1,q1) and (p2,q2) in a two-dimensional space is:\n",
    "distance = |p1-p2| + |q1-q2|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92511f5-c6bb-4e05-8549-55a244bfd796",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q10. What is the role of feature scaling in KNN?\n",
    "#Ans.\n",
    "#Feature scaling is the process of transforming the values of the features to have similar scales. \n",
    "#There are two common methods of feature scaling used in KNN: Min-max scaling, Standardization\n",
    "#Feature scaling ensures that all features have similar ranges and magnitudes, which helps to prevent any one feature from dominating the distance calculation. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
