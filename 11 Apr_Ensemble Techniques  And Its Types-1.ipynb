{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8343d256-a5f6-44a9-b6b9-02ec048dae9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1. What is an ensemble technique in machine learning?\n",
    "#Ans.\n",
    "#An ensemble technique in machine learning involves creating multiple individual models and then combining their predictions to make a final prediction. \n",
    "#The idea behind ensemble techniques is that the combination of multiple models can often lead to better predictions than any individual model. \n",
    "#Ensembles are typically used to improve the accuracy, robustness, and generalization of machine learning models. \n",
    "#Common examples of ensemble techniques include bagging, boosting, and stacking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d329d37d-c91c-474f-a165-8132b7fca424",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2. Why are ensemble techniques used in machine learning?\n",
    "#Ans.\n",
    "#Ensemble techniques are used in machine learning to improve the performance, accuracy, robustness, and generalization of a model. \n",
    "#By combining multiple models, ensemble techniques can help to mitigate the limitations or biases of any individual model, and can help to reduce the risk of overfitting\n",
    "#Overall, ensemble techniques are used in machine learning to create more accurate and reliable models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45de2f0a-05bd-4e70-836e-c7de01e794a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3. What is bagging?\n",
    "#Ans.\n",
    "#Bagging (Bootstrap Aggregating) is an ensemble technique in machine learning that involves creating multiple models using bootstrapped samples of the training data and then combining their predictions to make a final prediction. \n",
    "#The idea behind bagging is to reduce the variance of the individual models by creating multiple models that are diverse and less likely to overfit to the training data.\n",
    "#Bagging is often used with decision trees, but it can be applied to any machine learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19e0136-1851-4108-b91e-4dbd699c2dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4. What is boosting?\n",
    "#Ans.\n",
    "#Boosting is an ensemble technique in machine learning that involves creating a sequence of models, with each model trained to improve upon the weaknesses of the previous model. \n",
    "#In boosting, each model is trained on a weighted version of the training data, where the weights are increased for misclassified samples from the previous model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f2110a-6150-4982-83fd-7b06fdaaed48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5. What are the benefits of using ensemble techniques?\n",
    "#Ans.\n",
    "#The benefits of using ensemble techniques in machine learning are: Improved performance, Robustness, Generalization, Flexibility, Interpretability\n",
    "#Overall, ensemble techniques can help to create more accurate and reliable machine learning models that are better able to handle complex and noisy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4832e37a-4bbd-4d86-ac05-1a948a88271e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6. Are ensemble techniques always better than individual models?\n",
    "#Ans.\n",
    "#Ensemble techniques are not always better than individual models, and there are situations where an individual model may be more appropriate. \n",
    "#For example, if the data is relatively simple and contains few variables, a single model may be sufficient and ensemble techniques may not provide significant benefits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4923f2b1-543e-44a0-af6a-d842a3bec94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7. How is the confidence interval calculated using bootstrap?\n",
    "#Ans.\n",
    "#Bootstrap is a resampling technique that involves repeatedly sampling from the original dataset to create new datasets, and then using these new datasets to estimate the sampling distribution of a statistic of interest.\n",
    "#To calculate the confidence interval using bootstrap, we follow these steps:\n",
    "\n",
    "#Take a sample of size n from the original dataset.\n",
    "#Repeat this process B times to create B bootstrap samples.\n",
    "#Calculate the statistic of interest (e.g., mean, median, standard deviation, etc.) for each of the B bootstrap samples.\n",
    "#Calculate the mean and standard deviation of the B bootstrap statistics.\n",
    "#Use the mean and standard deviation of the bootstrap statistics to calculate the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8679a4-384c-4397-9b5f-226d7674e82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q8. How does bootstrap work and What are the steps involved in bootstrap?\n",
    "#Ans.\n",
    "#Bootstrap is a resampling technique that is used to estimate the sampling distribution of a statistic.\n",
    "#The steps involved in bootstrap are as follows:\n",
    "\n",
    "#Take a random sample of size n (the same size as the original dataset) from the original dataset.\n",
    "#Calculate the statistic of interest (e.g., mean, median, standard deviation, etc.) for the sample.\n",
    "#Repeat steps 1 and 2 B times to create B bootstrap samples and obtain B bootstrap statistics.\n",
    "#Calculate the mean, standard deviation, and other descriptive statistics of the B bootstrap statistics.\n",
    "#Use the bootstrap statistics to estimate the sampling distribution of the statistic of interest and calculate the standard error, confidence interval, and other inferential statistics as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b85da3d-6792-4951-8a5f-6aadc87cd2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence Interval: [14.90, 15.34]\n"
     ]
    }
   ],
   "source": [
    "#Q9. A researcher wants to estimate the mean height of a population of trees. They measure the height of a sample of 50 trees and obtain a mean height of 15 meters and a standard deviation of 2 meters. Use bootstrap to estimate the 95% confidence interval for the population mean height.\n",
    "#Ans.\n",
    "#To estimate the 95% confidence interval for the population mean height using bootstrap, we can follow these steps:\n",
    "import numpy as np\n",
    "\n",
    "# Define the sample of tree heights\n",
    "sample = np.array([15.2, 14.8, 16.5, 14.1, 13.9, 15.7, 16.4, 15.9, 13.4, 15.1,\n",
    "                   14.6, 14.5, 15.2, 14.7, 16.1, 15.6, 15.0, 15.8, 13.8, 15.3,\n",
    "                   14.3, 14.9, 14.2, 15.2, 14.8, 15.3, 15.0, 16.3, 14.7, 14.4,\n",
    "                   16.0, 15.4, 15.9, 14.0, 15.2, 15.1, 16.2, 14.5, 15.1, 13.5,\n",
    "                   14.6, 14.9, 15.5, 16.1, 15.6, 16.4, 15.7, 13.8, 15.4, 16.2])\n",
    "\n",
    "# Calculate the mean and standard deviation of the sample\n",
    "sample_mean = np.mean(sample)\n",
    "sample_std = np.std(sample, ddof=1)\n",
    "\n",
    "# Set the number of bootstrap samples\n",
    "B = 10000\n",
    "\n",
    "# Initialize an array to store the bootstrap sample means\n",
    "bootstrap_means = np.zeros(B)\n",
    "\n",
    "# Generate the bootstrap samples and calculate the sample means\n",
    "for i in range(B):\n",
    "    bootstrap_sample = np.random.choice(sample, size=50, replace=True)\n",
    "    bootstrap_means[i] = np.mean(bootstrap_sample)\n",
    "\n",
    "# Calculate the 2.5th and 97.5th percentiles of the bootstrap distribution\n",
    "ci_lower = np.percentile(bootstrap_means, 2.5)\n",
    "ci_upper = np.percentile(bootstrap_means, 97.5)\n",
    "\n",
    "# Print the 95% confidence interval for the population mean height\n",
    "print(\"95% Confidence Interval: [{:.2f}, {:.2f}]\".format(ci_lower, ci_upper))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
