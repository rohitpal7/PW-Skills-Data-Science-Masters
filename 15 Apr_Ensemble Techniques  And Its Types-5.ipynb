{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e8975e4-977a-4282-b8f2-f58295e60c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1. You are working on a machine learning project where you have a dataset containing numerical and categorical features. You have identified that some of the features are highly correlated and there are missing values in some of the columns. You want to build a pipeline that automates the feature engineering process and handles the missing valuesD\n",
    "#Ans.\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('dataset.csv')\n",
    "\n",
    "# Separate the target variable from the features\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Define the column transformer for numerical and categorical features\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', num_transformer, X.select_dtypes(include=['float', 'int'])),\n",
    "    ('cat', cat_transformer, X.select_dtypes(include=['object']))\n",
    "])\n",
    "\n",
    "# Define the feature selection method\n",
    "selector = SelectKBest(score_func=f_classif, k=10)\n",
    "\n",
    "# Define the classifier\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Define the pipeline\n",
    "pipe = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selector', selector),\n",
    "    ('clf', clf)\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the pipeline on the test data\n",
    "accuracy = pipe.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ed74a7a-9cc3-440d-83d7-7bec581b891e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8032786885245902\n"
     ]
    }
   ],
   "source": [
    "#Q2. Build a pipeline that includes a random forest classifier and a logistic regress#on classifier, and then use a voting classifier to combine the#r predictions. Train the pipeline on the iris dataset and evaluate its accuracy.\n",
    "#Ans.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "# Assuming X is the feature matrix and y is the target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Define the pipelines for the Random Forest Classifier and Logistic Regression Classifier\n",
    "rf_pipeline = Pipeline([\n",
    "    ('rf_imputer', SimpleImputer(strategy='mean')),\n",
    "    ('rf_scaler', StandardScaler()),\n",
    "    ('rf_classifier', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "lr_pipeline = Pipeline([\n",
    "    ('lr_imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('lr_onehot', OneHotEncoder(handle_unknown='ignore')),\n",
    "    ('lr_classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Define the voting classifier\n",
    "voting_classifier = VotingClassifier(\n",
    "    estimators=[('rf', rf_pipeline), ('lr', lr_pipeline)],\n",
    "    voting='soft' # using soft voting to take probabilities into account\n",
    ")\n",
    "\n",
    "# Train the voting classifier\n",
    "voting_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the accuracy of the voting classifier on the test dataset\n",
    "y_pred = voting_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
